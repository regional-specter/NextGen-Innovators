{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install and Import Libraries**\n",
    "\n",
    "This section installs and imports the necessary libraries for building the image classification model, including TensorFlow for building and training the model, and other libraries for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Preprocess Data**\n",
    "\n",
    "This section defines utility functions to handle image data. It includes a function to check for corrupted images to ensure data quality. The main part loads the images from the specified directory, extracts labels from filenames, and filters out any corrupted images before preparing them for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def is_image_corrupted(filepath):\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            img.verify()\n",
    "        return False\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f'Corrupted image: {filepath}, error: {e}')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 images.\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            if not is_image_corrupted(filepath):\n",
    "                label = filename.split('-')[0]\n",
    "                images.append(filepath)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "image_dir = 'images/'\n",
    "images, labels = load_data(image_dir)\n",
    "\n",
    "print(f'Loaded {len(images)} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data and Create Data Generators**\n",
    "\n",
    "The dataset is split into training and validation sets to evaluate the model's performance on unseen data. `ImageDataGenerator` is used to preprocess the images and apply data augmentation to the training set, which helps in preventing overfitting and improving model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
    "val_df = pd.DataFrame({'filename': X_val, 'class': y_val})\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 validated image filenames belonging to 2 classes.\n",
      "Found 60 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Model**\n",
    "\n",
    "A pre-trained model, MobileNetV2, is used as the base for our classifier. The top layers of the pre-trained model are frozen, and new custom layers are added for our specific classification task. This approach, known as transfer learning, leverages the powerful features learned by the base model on a large dataset, leading to faster and more accurate training on our smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameIterator' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m x = GlobalAveragePooling2D()(x)\n\u001b[32m      8\u001b[39m x = Dense(\u001b[32m1024\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(x)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m predictions = Dense(\u001b[43mtrain_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)(x)\n\u001b[32m     11\u001b[39m model = Model(inputs=base_model.input, outputs=predictions)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrameIterator' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and Train the Model**\n",
    "\n",
    "The model is compiled with the Adam optimizer and categorical cross-entropy loss function. It is then trained for a few epochs on the training data, and its performance is monitored on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Model**\n",
    "\n",
    "The model's performance is evaluated by plotting the training and validation accuracy and loss over epochs. This helps in visualizing how well the model is learning and generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "A confusion matrix is generated to provide a detailed breakdown of the model's classification performance for each class. It shows the number of correct and incorrect predictions, which helps in understanding the model's strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(val_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "cm = confusion_matrix(val_generator.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=val_generator.class_indices.keys(), yticklabels=val_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(val_generator.classes, y_pred, target_names=val_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict on a Sample Image**\n",
    "\n",
    "This section provides a function to predict the class of a single image. It loads an image, preprocesses it to match the model's input requirements, and then uses the trained model to make a prediction. The predicted class with the highest probability is then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(filepath, model, class_indices):\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "    class_labels = {v: k for k, v in class_indices.items()}\n",
    "    return class_labels[predicted_class[0]]\n",
    "\n",
    "sample_image = 'images/greater-flamingo-1.jpeg'\n",
    "predicted_label = predict_image(sample_image, model, train_generator.class_indices)\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**\n",
    "\n",
    "The trained model, including its architecture and weights, is saved to a file. This allows for easy reuse in the future without needing to retrain. The class mappings are also saved to a JSON file for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('artifacts/visual_classifier_2.keras')\n",
    "\n",
    "import json\n",
    "class_indices = train_generator.class_indices\n",
    "class_mapping = {v: k for k, v in class_indices.items()}\n",
    "with open('artifacts/class_mapping_2.json', 'w') as f:\n",
    "    json.dump(class_mapping, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
