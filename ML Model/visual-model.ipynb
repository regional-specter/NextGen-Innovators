{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785f6e56",
   "metadata": {},
   "source": [
    "# **Visual Sound Detection Model**\\n",
    "\\n",
    "This notebook builds a computer vision classifier that learns from images located in the `images` folder. Each image file name is interpreted as its label. The pipeline covers environment setup, data ingestion, preprocessing, model training, evaluation, and an optional realtime webcam inference demo.\\n",
    "\\n",
    "> **Note:** Add your images to `images/` before running the training steps. The notebook assumes a standard RGB image format (e.g., `.jpg`, `.png`).\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\\n",
    "import sys\\n",
    "import math\\n",
    "import json\\n",
    "from pathlib import Path\\n",
    "from typing import Callable, Dict, List, Tuple\\n",
    "\\n",
    "import numpy as np\\n",
    "import pandas as pd\\n",
    "from PIL import Image\\n",
    "\\n",
    "import tensorflow as tf\\n",
    "from tensorflow import keras\\n",
    "from tensorflow.keras import layers\\n",
    "\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "from sklearn.metrics import classification_report, confusion_matrix\\n",
    "\\n",
    "# Optional: used later for webcam capture\\n",
    "try:\\n",
    "    import cv2\\n",
    "except ImportError:\\n",
    "    cv2 = None\\n",
    "    print(\\"OpenCV (cv2) not found. Webcam inference cell will guide you through installing it.\\")\\n",
    "\\n",
    "# Configure paths\\n",
    "PROJECT_ROOT = Path(\\"/Users/raoabdul/Documents/Development/NextGen-Innovators/ML Model\\")\\n",
    "IMAGE_DIR = PROJECT_ROOT / \\"images\\"\\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \\"artifacts\\"\\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\\n",
    "\\n",
    "# Basic reproducibility\\n",
    "SEED = 42\\n",
    "np.random.seed(SEED)\\n",
    "tf.random.set_seed(SEED)\\n",
    "\\n",
    "print(f\\"TensorFlow version: {tf.__version__}\\")\\n",
    "print(f\\"Looking for images in: {IMAGE_DIR}\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e062f2",
   "metadata": {},
   "source": [
    "## **1. Dataset Discovery & Label Parsing**\\n",
    "\\n",
    "This section scans the `images` directory, extracts labels from file names, and builds a dataframe describing the dataset. Customize `extract_label_from_name` if you prefer a different naming convention.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32830b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_name(filename: str) -> str:\\n",
    "    \\\"\\\"\\\"Derive a label from the image filename (without the extension).\\n",
    "\\n",
    "    Strategy:\\n",
    "      1. Remove the file extension.\\n",
    "      2. Split on underscores, dashes, or spaces.\\n",
    "      3. Use the first token as the class name.\\n",
    "\\n",
    "    Adjust this heuristic to match your naming scheme.\\n",
    "    \\\"\\\"\\\"\\n",
    "    stem = Path(filename).stem\\n",
    "    for delimiter in (\\"_\\", \\"-\\", \\" \\"):\\n",
    "        if delimiter in stem:\\n",
    "            return stem.split(delimiter)[0].lower()\\n",
    "    return stem.lower()\\n",
    "\\n",
    "\\n",
    "def discover_dataset(image_dir: Path) -> pd.DataFrame:\\n",
    "    \\\"\\\"\\\"Return a dataframe with columns [path, label].\\\"\\\"\\\"\\n",
    "    image_paths = sorted(\\n",
    "        p for p in image_dir.glob(\\"**/*\\") if p.is_file() and p.suffix.lower() in {\\".jpg\\", \\".jpeg\\", \\".png\\", \\".bmp\\"}\\n",
    "    )\\n",
    "    if not image_paths:\\n",
    "        raise FileNotFoundError(\\n",
    "            f\\"No images found in {image_dir}. Add files before running training.\\"\\n",
    "        )\\n",
    "    records = []\\n",
    "    for path in image_paths:\\n",
    "        label = extract_label_from_name(path.name)\\n",
    "        records.append({\\"path\\": path, \\"label\\": label})\\n",
    "    df = pd.DataFrame(records)\\n",
    "    return df\\n",
    "\\n",
    "\\n",
    "def summarize_dataset(df: pd.DataFrame) -> None:\\n",
    "    \\\"\\\"\\\"Print summary statistics and plot label distribution.\\\"\\\"\\\"\\n",
    "    print(f\\"Total images: {len(df)}\\")\\n",
    "    label_counts = df[\\"label\\"].value_counts().sort_values(ascending=False)\\n",
    "    print(\\"Label distribution:\\")\\n",
    "    print(label_counts)\\n",
    "\\n",
    "    plt.figure(figsize=(10, 4))\\n",
    "    sns.barplot(x=label_counts.index, y=label_counts.values, palette=\\"viridis\\")\\n",
    "    plt.xticks(rotation=45, ha=\\"right\\")\\n",
    "    plt.xlabel(\\"Label\\")\\n",
    "    plt.ylabel(\\"Count\\")\\n",
    "    plt.title(\\"Image count per label\\")\\n",
    "    plt.tight_layout()\\n",
    "    plt.show()\\n",
    "\\n",
    "\\n",
    "def train_val_test_split(\\n",
    "    df: pd.DataFrame,\\n",
    "    train_frac: float = 0.7,\\n",
    "    val_frac: float = 0.2,\\n",
    "    test_frac: float = 0.1,\\n",
    "    seed: int = 42,\\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\\n",
    "    \\\"\\\"\\\"\\n",
    "    Split the dataframe into train/validation/test subsets stratified by label.\\n",
    "    For very small datasets (<20 images total), adjusts splits automatically.\\n",
    "    \\\"\\\"\\\"\\n",
    "    if not math.isclose(train_frac + val_frac + test_frac, 1.0, rel_tol=1e-5):\\n",
    "        raise ValueError(\\"train_frac + val_frac + test_frac must sum to 1.0\\")\\n",
    "\\n",
    "    total_images = len(df)\\n",
    "    num_classes = len(df[\\"label\\"].unique())\\n",
    "    images_per_class = total_images // num_classes if num_classes > 0 else 0\\n",
    "\\n",
    "    # Adjust splits for very small datasets\\n",
    "    if total_images < 20:\\n",
    "        # For very small datasets, use larger train split, skip test if too small\\n",
    "        train_frac = 0.80\\n",
    "        val_frac = 0.10\\n",
    "        test_frac = 0.10\\n",
    "        print(f\\"âš ï¸  Very small dataset detected ({total_images} images). Using adjusted splits: 85% train, 15% val, 0% test\\")\\n",
    "\\n",
    "    df_shuffled = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\\n",
    "    splits: Dict[str, List[pd.Series]] = {\\"train\\": [], \\"val\\": [], \\"test\\": []}\\n",
    "\\n",
    "    for label, group in df_shuffled.groupby(\\"label\\"):\\n",
    "        n = len(group)\\n",
    "        n_train = max(1, int(n * train_frac))\\n",
    "        n_val = max(1, int(n * val_frac)) if n >= 3 and val_frac > 0 else 0\\n",
    "        n_test = n - n_train - n_val if test_frac > 0 else 0\\n",
    "        splits[\\"train\\"].append(group.iloc[:n_train])\\n",
    "        if n_val > 0:\\n",
    "            splits[\\"val\\"].append(group.iloc[n_train : n_train + n_val])\\n",
    "        if n_test > 0:\\n",
    "            splits[\\"test\\"].append(group.iloc[n_train + n_val :])\\n",
    "\\n",
    "    train_df = pd.concat(splits[\\"train\\"]).reset_index(drop=True)\\n",
    "    val_df = pd.concat(splits[\\"val\\"]).reset_index(drop=True) if splits[\\"val\\"] else pd.DataFrame()\\n",
    "    test_df = pd.concat(splits[\\"test\\"]).reset_index(drop=True) if splits[\\"test\\"] else pd.DataFrame()\\n",
    "\\n",
    "    print(\\n",
    "        f\\"Split counts -> train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\\"\\n",
    "    )\\n",
    "    return train_df, val_df, test_df\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\\n",
    "    dataset_df = discover_dataset(IMAGE_DIR)\\n",
    "    print(dataset_df.head())\\n",
    "    summarize_dataset(dataset_df)\\n",
    "except FileNotFoundError as e:\\n",
    "    dataset_df = None\\n",
    "    print(e)\\n",
    "    print(\\"Populate the images directory and rerun this cell when ready.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d6ed1",
   "metadata": {},
   "source": [
    "## **2. Preprocessing Pipeline**\\n",
    "\\n",
    "This section builds TensorFlow `tf.data.Dataset` pipelines with on-the-fly preprocessing and optional augmentation. Adjust the image size or augmentations to suit your dataset.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\\n",
    "BATCH_SIZE = 16\\n",
    "AUTOTUNE = tf.data.AUTOTUNE\\n",
    "\\n",
    "\\n",
    "def load_image(path: tf.Tensor) -> tf.Tensor:\\n",
    "    \\\"\\\"\\\"Load an image from disk and resize it.\\\"\\\"\\\"\\n",
    "    image = tf.io.read_file(path)\\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\\n",
    "    image = tf.image.resize(image, IMG_SIZE)\\n",
    "    return image\\n",
    "\\n",
    "\\n",
    "def build_dataset(\\n",
    "    df: pd.DataFrame,\\n",
    "    class_to_index: Dict[str, int],\\n",
    "    augment: bool = False,\\n",
    "    aggressive_augment: bool = False,\\n",
    "    very_small_dataset: bool = False,\\n",
    ") -> tf.data.Dataset:\\n",
    "    paths = df[\\"path\\"].astype(str).values\\n",
    "    labels = df[\\"label\\"].map(class_to_index).values\\n",
    "\\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\\n",
    "\\n",
    "    def _load_and_preprocess(path, label):\\n",
    "        image = load_image(path)\\n",
    "        if augment:\\n",
    "            image = augment_image(image, aggressive=aggressive_augment, very_small_dataset=very_small_dataset)\\n",
    "        return image, tf.one_hot(label, depth=len(class_to_index))\\n",
    "\\n",
    "    ds = ds.shuffle(len(df), seed=SEED)\\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\\n",
    "    return ds\\n",
    "\\n",
    "\\n",
    "def augment_image(image: tf.Tensor, aggressive: bool = True, very_small_dataset: bool = False) -> tf.Tensor:\\n",
    "    \\\"\\\"\\\"\\n",
    "    Apply data augmentation. \\n",
    "    - aggressive=True: Standard aggressive augmentation\\n",
    "    - very_small_dataset=True: Maximum augmentation for datasets <15 images per class\\n",
    "    \\\"\\\"\\\"\\n",
    "    # Random flips (always applied)\\n",
    "    image = tf.image.random_flip_left_right(image)\\n",
    "    image = tf.image.random_flip_up_down(image)\\n",
    "    \\n",
    "    if very_small_dataset:\\n",
    "        # MAXIMUM augmentation for very small datasets (11 images per class)\\n",
    "        # Color augmentations\\n",
    "        image = tf.image.random_brightness(image, max_delta=0.4)\\n",
    "        image = tf.image.random_contrast(image, 0.6, 1.4)\\n",
    "        image = tf.image.random_saturation(image, 0.5, 1.5)\\n",
    "        image = tf.image.random_hue(image, max_delta=0.15)\\n",
    "        \\n",
    "        # Geometric augmentations\\n",
    "        # Random rotation (90 degree increments)\\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\\n",
    "        \\n",
    "        # Random zoom via crop and resize\\n",
    "        crop_size = int(IMG_SIZE[0] * tf.random.uniform([], 0.7, 0.95))\\n",
    "        if crop_size > 0:\\n",
    "            image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\\n",
    "            image = tf.image.resize(image, IMG_SIZE)\\n",
    "        \\n",
    "        # Random translation (shift)\\n",
    "        image = tf.image.random_crop(image, size=[int(IMG_SIZE[0]*0.9), int(IMG_SIZE[1]*0.9), 3])\\n",
    "        image = tf.image.resize(image, IMG_SIZE)\\n",
    "        \\n",
    "    elif aggressive:\\n",
    "        # Standard aggressive augmentation\\n",
    "        image = tf.image.random_brightness(image, max_delta=0.3)\\n",
    "        image = tf.image.random_contrast(image, 0.7, 1.3)\\n",
    "        image = tf.image.random_saturation(image, 0.6, 1.4)\\n",
    "        image = tf.image.random_hue(image, max_delta=0.1)\\n",
    "        # Random rotation (90 degree increments)\\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\\n",
    "        # Random zoom via crop and resize\\n",
    "        crop_size = int(IMG_SIZE[0] * 0.8)\\n",
    "        if crop_size > 0:\\n",
    "            image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\\n",
    "            image = tf.image.resize(image, IMG_SIZE)\\n",
    "    else:\\n",
    "        # Mild augmentation\\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\\n",
    "        image = tf.image.random_contrast(image, 0.9, 1.1)\\n",
    "    \\n",
    "    # Ensure values stay in [0, 1]\\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\\n",
    "    return image\\n",
    "\\n",
    "\\n",
    "def prepare_datasets(df: pd.DataFrame):\n",
    "    labels = sorted(df[\\"label\\"].unique())\\n",
    "    class_to_index = {label: idx for idx, label in enumerate(labels)}\\n",
    "    index_to_class = {idx: label for label, idx in class_to_index.items()}\\n",
    "\\n",
    "    # Detect dataset size and choose augmentation strategy\\n",
    "    total_images = len(df)\\n",
    "    num_classes = len(labels)\\n",
    "    images_per_class = total_images // num_classes if num_classes > 0 else 0\\n",
    "    \\n",
    "    # Determine augmentation level\\n",
    "    use_very_small_aug = images_per_class < 15  # Maximum augmentation for very small datasets\\n",
    "    use_aggressive_aug = images_per_class < 50 and not use_very_small_aug  # Standard aggressive for small datasets\\n",
    "\\n",
    "    train_df, val_df, test_df = train_val_test_split(df)\\n",
    "\\n",
    "    train_ds = build_dataset(\\n",
    "        train_df, \\n",
    "        class_to_index, \\n",
    "        augment=True, \\n",
    "        aggressive_augment=use_aggressive_aug,\\n",
    "        very_small_dataset=use_very_small_aug\\n",
    "    )\\n",
    "    val_ds = build_dataset(val_df, class_to_index, augment=False) if len(val_df) > 0 else None\\n",
    "    test_ds = build_dataset(test_df, class_to_index, augment=False) if len(test_df) > 0 else None\\n",
    "\\n",
    "    return {\\n",
    "        \\"train\\": train_ds,\\n",
    "        \\"val\\": val_ds,\\n",
    "        \\"test\\": test_ds,\\n",
    "        \\"class_to_index\\": class_to_index,\\n",
    "        \\"index_to_class\\": index_to_class,\\n",
    "        \\"train_df\\": train_df,\\n",
    "        \\"val_df\\": val_df,\\n",
    "        \\"test_df\\": test_df,\\n",
    "    }\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_df is not None:\\n",
    "    data_bundle = prepare_datasets(dataset_df)\\n",
    "else:\\n",
    "    data_bundle = None\\n",
    "    print(\\"Dataset not prepared yet. Populate images and rerun.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28dd4f",
   "metadata": {},
   "source": [
    "## **3. Model Architecture**\\n",
    "\\n",
    "For small datasets, we use transfer learning with MobileNetV2. This involves:\\n",
    "1. **Loading a pre-trained model:** Using weights from ImageNet.\\n",
    "2. **Freezing the base model:** Initially, we only train the new classification layers.\\n",
    "3. **Fine-tuning:** After the head has learned, we unfreeze some of the top layers of the base model and train with a very low learning rate.\\n",
    "\\n",
    "This approach helps prevent overfitting and leverages the features learned from a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(num_classes: int, fine_tune: bool = False) -> keras.Model:\\n",
    "    \\\"\\\"\\\"Builds a classifier using MobileNetV2 for transfer learning.\\\"\\\"\\\"\\n",
    "    base_model = keras.applications.MobileNetV2(\\n",
    "        input_shape=(*IMG_SIZE, 3),\\n",
    "        include_top=False,\\n",
    "        weights='imagenet'\\n",
    "    )\\n",
    "\\n",
    "    if fine_tune:\\n",
    "        base_model.trainable = True\\n",
    "        # Unfreeze more layers for fine-tuning on a small dataset\\n",
    "        for layer in base_model.layers[:-40]:\\n",
    "            layer.trainable = False\\n",
    "        print(\\"ðŸ”§ Fine-tuning enabled: Last 40 layers of base model are trainable\\")\\n",
    "    else:\\n",
    "        base_model.trainable = False\\n",
    "        print(\\"ðŸ”’ Base model frozen: Only classification head will be trained\\")\\n",
    "\\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\\n",
    "    x = base_model(x, training=fine_tune)\\n",
    "    x = layers.GlobalAveragePooling2D()(x)\\n",
    "    x = layers.Dropout(0.5)(x)  # Increased dropout for regularization\\n",
    "    x = layers.Dense(256, activation=\\"relu\\")(x) # Larger dense layer\\n",
    "    x = layers.Dropout(0.5)(x)\\n",
    "    outputs = layers.Dense(num_classes, activation=\\"softmax\\")(x)\\n",
    "    \\n",
    "    model = keras.Model(inputs, outputs, name=\\"visual_classifier\\")\\n",
    "    return model\\n",
    "\\n",
    "if data_bundle is not None:\\n",
    "    num_classes = len(data_bundle[\\"class_to_index\\"])\\n",
    "    model = build_classifier(num_classes, fine_tune=False) # Start with frozen base\\n",
    "    model.compile(\\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\\n",
    "        loss=\\"categorical_crossentropy\\",\\n",
    "        metrics=[\\"accuracy\\"]\\n",
    "    )\\n",
    "    model.summary()\\n",
    "else:\\n",
    "    model = None\\n",
    "    print(\\"Model not built. Please prepare the dataset first.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad2672",
   "metadata": {},
   "source": [
    "## **4. Training the Model**\\n",
    "\\n",
    "We use a two-stage training process:\\n",
    "1. **Stage 1:** Train the classification head with the base model frozen.\\n",
    "2. **Stage 2:** Unfreeze the top layers of the base model and fine-tune with a low learning rate.\\n",
    "\\n",
    "Callbacks like `EarlyStopping` and `ReduceLROnPlateau` are used to optimize training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_STAGE1 = 20\\n",
    "EPOCHS_STAGE2 = 30\\n",
    "\\n",
    "if data_bundle is not None and model is not None:\\n",
    "    # Callbacks\\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\\n",
    "\\n",
    "    # Stage 1: Train the head\\n",
    "    print(\\"--- Stage 1: Training Classification Head ---\\")\\n",
    "    history1 = model.fit(\\n",
    "        data_bundle[\\"train\\"],\\n",
    "        validation_data=data_bundle[\\"val\\"],\\n",
    "        epochs=EPOCHS_STAGE1,\\n",
    "        callbacks=[early_stopping, reduce_lr],\\n",
    "        verbose=1\\n",
    "    )\\n",
    "\\n",
    "    # Stage 2: Fine-tune the model\\n",
    "    print(\\"--- Stage 2: Fine-tuning Model ---\\")\\n",
    "    model = build_classifier(num_classes, fine_tune=True)\\n",
    "    model.compile(\\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-5), # Lower learning rate\\n",
    "        loss=\\"categorical_crossentropy\\",\\n",
    "        metrics=[\\"accuracy\\"]\\n",
    "    )\\n",
    "\\n",
    "    history2 = model.fit(\\n",
    "        data_bundle[\\"train\\"],\\n",
    "        validation_data=data_bundle[\\"val\\"],\\n",
    "        epochs=EPOCHS_STAGE2,\\n",
    "        callbacks=[early_stopping, reduce_lr],\\n",
    "        verbose=1\\n",
    "    )\\n",
    "\\n",
    "    # Combine histories\\n",
    "    history = {k: history1.history.get(k, []) + history2.history.get(k, []) for k in set(list(history1.history.keys()) + list(history2.history.keys()))}\\n",
    "else:\\n",
    "    history = None\\n",
    "    print(\\"Training skipped. Data or model not available.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474380d4",
   "metadata": {},
   "source": [
    "## **5. Evaluation**\\n",
    "\\n",
    "We visualize the training history and evaluate the model's performance on the test set using a classification report and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2248f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict) -> None:\\n",
    "    metrics = [\\"accuracy\\", \\"loss\\"]\\n",
    "    plt.figure(figsize=(12, 4))\\n",
    "    for i, metric in enumerate(metrics):\\n",
    "        plt.subplot(1, 2, i + 1)\\n",
    "        plt.plot(history[metric], label=f\\"Train {metric.capitalize()}\\")\\n",
    "        plt.plot(history[f'val_{metric}'], label=f\\"Val {metric.capitalize()}\\")\\n",
    "        plt.xlabel(\\"Epochs\\")\\n",
    "        plt.ylabel(metric.capitalize())\\n",
    "        plt.legend()\\n",
    "    plt.show()\\n",
    "\\n",
    "if history:\\n",
    "    plot_history(history)\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a88f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_bundle and data_bundle.get(\\"test\\") and model:\\n",
    "    print(\\"--- Evaluating on Test Set ---\\")\\n",
    "    test_loss, test_acc = model.evaluate(data_bundle[\\"test\\"])\\n",
    "    print(f\\"Test Accuracy: {test_acc:.4f}\\")\\n",
    "\\n",
    "    y_pred_probs = model.predict(data_bundle[\\"test\\"])\\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\\n",
    "    y_true = np.concatenate([y for x, y in data_bundle[\\"test\\"]], axis=0)\\n",
    "    y_true = np.argmax(y_true, axis=1)\\n",
    "\\n",
    "    class_names = list(data_bundle[\\"class_to_index\\"].keys())\\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\\n",
    "\\n",
    "    cm = confusion_matrix(y_true, y_pred)\\n",
    "    plt.figure(figsize=(8, 6))\\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\\n",
    "    plt.xlabel(\\"Predicted\\")\\n",
    "    plt.ylabel(\\"True\\")\\n",
    "    plt.title(\\"Confusion Matrix\\")\\n",
    "    plt.show()\\n",
    "else:\\n",
    "    print(\\"Evaluation skipped. Test data or model not available.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e57b9",
   "metadata": {},
   "source": [
    "## **6. Save the Model**\\n",
    "\\n",
    "Finally, we save the trained model and the class mapping for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and data_bundle is not None:\\n",
    "    model.save(ARTIFACT_DIR / \\"visual_classifier.keras\\")\\n",
    "    with open(ARTIFACT_DIR / \\"class_mapping.json\\", \\"w\\") as f:\\n",
    "        # convert keys to string for json serialization\\n",
    "        string_class_mapping = {str(k): v for k, v in data_bundle[\\"index_to_class\\"].items()}\\n",
    "        json.dump(string_class_mapping, f, indent=4)\\n",
    "    print(f\\"Model saved to {ARTIFACT_DIR / 'visual_classifier.keras'}\\" )\\n",
    "    print(f\\"Class mapping saved to {ARTIFACT_DIR / 'class_mapping.json'}\\" )\\n",
    "else:\\n",
    "    print(\\"Model not saved. Not available.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_inference_markdown",
   "metadata": {},
   "source": [
    "## **7. Single Image Inference**\\n",
    "\\n",
    "Use the helper below to classify individual images. Provide a path to any image file after training."
   ]
  },
  {
   "cell_type": "code",
   "id": "new_inference_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(path: Path, model: keras.Model, index_to_class: Dict[int, str]) -> Dict[str, float]:\\n",
    "    image = load_image(tf.convert_to_tensor(str(path)))\\n",
    "    image = tf.expand_dims(image, axis=0)\\n",
    "    preds = model.predict(image, verbose=0)[0]\\n",
    "    return {\\n",
    "        index_to_class[idx]: float(prob)\\n",
    "        for idx, prob in enumerate(preds)\\n",
    "    }\\n",
    "\\n",
    "\\n",
    "def display_prediction(predictions: Dict[str, float]) -> None:\\n",
    "    items = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\\n",
    "    for label, prob in items:\\n",
    "        print(f\\"{label}: {prob:.3f}\\" )\\n",
    "\\n",
    "\\n",
    "# Example usage (update the path after adding images)\\n",
    "example_image_path = IMAGE_DIR / \\"sample-image.jpeg\\"\\n",
    "if model is not None and example_image_path.exists():\\n",
    "    probs = predict_image(example_image_path, model, data_bundle[\\"index_to_class\\"])\\n",
    "    display_prediction(probs)\\n",
    "else:\\n",
    "    print(\\"Set `example_image_path` to an existing image after training to see predictions.\\")\\n"
   ]
  }\\n",
  {
   "cell_type": "markdown",
   "id": "664b92e7",
   "metadata": {},
   "source": [
    "## **8. Save and Reload Model**\\n",
    "\\n",
    "Persist the trained model and provide a simple loader. This allows you to reuse the classifier without retraining every session.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ARTIFACT_DIR / \\"visual_classifier.keras\\"\\n",
    "METADATA_PATH = ARTIFACT_DIR / \\"class_mapping.json\\"\\n",
    "\\n",
    "if model is not None and data_bundle is not None:\\n",
    "    model.save(MODEL_PATH)\\n",
    "    with open(METADATA_PATH, \\"w\\") as f:\\n",
    "        json.dump(data_bundle[\\"index_to_class\\"], f, indent=2)\\n",
    "    print(f\\"Model saved to {MODEL_PATH}\\" )\\n",
    "    print(f\\"Class mapping saved to {METADATA_PATH}\\" )\\n",
    "else:\\n",
    "    print(\\"Model not saved. Train the model first.\\")\\n",
    "\\n",
    "\\n",
    "def load_model_and_mapping(model_path: Path, metadata_path: Path):\\n",
    "    loaded_model = keras.models.load_model(model_path)\\n",
    "    with open(metadata_path) as f:\\n",
    "        index_to_class = {int(k): v for k, v in json.load(f).items()}\\n",
    "    return loaded_model, index_to_class\\n",
    "\\n",
    "\\n",
    "# Example reload usage (uncomment after training and saving)\\n",
    "# reloaded_model, index_to_class = load_model_and_mapping(MODEL_PATH, METADATA_PATH)\\n",
    "# display_prediction(predict_image(example_image_path, reloaded_model, index_to_class))\\n"
   ]
  },\\n",
  {
   "cell_type": "markdown",
   "id": "b41943af",
   "metadata": {},
   "source": [
    "## **9. Next Steps Checklist**\\n",
    "\\n",
    "- Add class-balanced images into `images/`.\\n",
    "- Run the notebook sequentially from top to bottom.\\n",
    "- Monitor training curves and adjust hyperparameters as needed.\\n",
    "- Test with realtime webcam inference once satisfied with model accuracy.\\n",
    "- Consider augmenting the dataset or using transfer learning for improved performance.\\n"
   ]
  }\\n",
  {
   "cell_type": "markdown",
   "id": "664b92e7",
   "metadata": {},
   "source": [
    "## **8. Save and Reload Model**\\n",
    "\\n",
    "Persist the trained model and provide a simple loader. This allows you to reuse the classifier without retraining every session.\\n"
   ]
  },\\n",
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ARTIFACT_DIR / \\"visual_classifier.keras\\"\\n",
    "METADATA_PATH = ARTIFACT_DIR / \\"class_mapping.json\\"\\n",
    "\\n",
    "if model is not None and data_bundle is not None:\\n",
    "    model.save(MODEL_PATH)\\n",
    "    with open(METADATA_PATH, \\"w\\") as f:\\n",
    "        json.dump(data_bundle[\\"index_to_class\\"], f, indent=2)\\n",
    "    print(f\\"Model saved to {MODEL_PATH}\\" )\\n",
    "    print(f\\"Class mapping saved to {METADATA_PATH}\\" )\\n",
    "else:\\n",
    "    print(\\"Model not saved. Train the model first.\\")\\n",
    "\\n",
    "\\n",
    "def load_model_and_mapping(model_path: Path, metadata_path: Path):\\n",
    "    loaded_model = keras.models.load_model(model_path)\\n",
    "    with open(metadata_path) as f:\\n",
    "        index_to_class = {int(k): v for k, v in json.load(f).items()}\\n",
    "    return loaded_model, index_to_class\\n",
    "\\n",
    "\\n",
    "# Example reload usage (uncomment after training and saving)\\n",
    "# reloaded_model, index_to_class = load_model_and_mapping(MODEL_PATH, METADATA_PATH)\\n",
    "# display_prediction(predict_image(example_image_path, reloaded_model, index_to_class))\\n"
   ]
  }\\n",
  {
   "cell_type": "markdown",
   "id": "b41943af",
   "metadata": {},
   "source": [
    "## **9. Next Steps Checklist**\\n",
    "\\n",
    "- Add class-balanced images into `images/`.\\n",
    "- Run the notebook sequentially from top to bottom.\\n",
    "- Monitor training curves and adjust hyperparameters as needed.\\n",
    "- Test with realtime webcam inference once satisfied with model accuracy.\\n",
    "- Consider augmenting the dataset or using transfer learning for improved performance.\\n"
   ]
  }\\n",
  {
   "cell_type": "markdown",
   "id": "664b92e7",
   "metadata": {},
   "source": [
    "## **8. Save and Reload Model**\\n",
    "\\n",
    "Persist the trained model and provide a simple loader. This allows you to reuse the classifier without retraining every session.\\n"
   ]
  },\\n",
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ARTIFACT_DIR / \\"visual_classifier.keras\\"\\n",
    "METADATA_PATH = ARTIFACT_DIR / \\"class_mapping.json\\"\\n",
    "\\n",
    "if model is not None and data_bundle is not None:\\n",
    "    model.save(MODEL_PATH)\\n",
    "    with open(METADATA_PATH, \\"w\\") as f:\\n",
    "        json.dump(data_bundle[\\"index_to_class\\"], f, indent=2)\\n",
    "    print(f\\"Model saved to {MODEL_PATH}\\" )\\n",
    "    print(f\\"Class mapping saved to {METADATA_PATH}\\" )\\n",
    "else:\\n",
    "    print(\\"Model not saved. Train the model first.\\")\\n",
    "\\n",
    "\\n",
    "def load_model_and_mapping(model_path: Path, metadata_path: Path):\\n",
    "    loaded_model = keras.models.load_model(model_path)\\n",
    "    with open(metadata_path) as f:\\n",
    "        index_to_class = {int(k): v for k, v in json.load(f).items()}\\n",
    "    return loaded_model, index_to_class\\n",
    "\\n",
    "\\n",
    "# Example reload usage (uncomment after training and saving)\\n",
    "# reloaded_model, index_to_class = load_model_and_mapping(MODEL_PATH, METADATA_PATH)\\n",
    "# display_prediction(predict_image(example_image_path, reloaded_model, index_to_class))\\n"
   ]
  }\\n",
  {
   "cell_type": "markdown",
   "id": "b41943af",
   "metadata": {},
   "source": [
    "## **9. Next Steps Checklist**\\n",
    "\\n",
    "- Add class-balanced images into `images/`.\\n",
    "- Run the notebook sequentially from top to bottom.\\n",
    "- Monitor training curves and adjust hyperparameters as needed.\\n",
    "- Test with realtime webcam inference once satisfied with model accuracy.\\n",
    "- Consider augmenting the dataset or using transfer learning for improved performance.\\n"
   ]
  }
 ]
}