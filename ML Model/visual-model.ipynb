{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785f6e56",
   "metadata": {},
   "source": [
    "# **Visual Sound Detection Model**\n",
    "\n",
    "This notebook builds a computer vision classifier that learns from images located in the `images` folder. Each image file name is interpreted as its label. The pipeline covers environment setup, data ingestion, preprocessing, model training, evaluation, and an optional realtime webcam inference demo.\n",
    "\n",
    "> **Note:** Add your images to `images/` before running the training steps. The notebook assumes a standard RGB image format (e.g., `.jpg`, `.png`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: used later for webcam capture\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    cv2 = None\n",
    "    print(\"OpenCV (cv2) not found. Webcam inference cell will guide you through installing it.\")\n",
    "\n",
    "# Configure paths\n",
    "PROJECT_ROOT = Path(\"/Users/raoabdul/Documents/Development/NextGen-Innovators/Ml Model\")\n",
    "IMAGE_DIR = PROJECT_ROOT / \"images\"\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Basic reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Looking for images in: {IMAGE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e062f2",
   "metadata": {},
   "source": [
    "## **1. Dataset Discovery & Label Parsing**\n",
    "\n",
    "This section scans the `images` directory, extracts labels from file names, and builds a dataframe describing the dataset. Customize `extract_label_from_name` if you prefer a different naming convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32830b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_name(filename: str) -> str:\n",
    "    \"\"\"Derive a label from the image filename (without the extension).\n",
    "\n",
    "    Strategy:\n",
    "      1. Remove the file extension.\n",
    "      2. Split on underscores, dashes, or spaces.\n",
    "      3. Use the first token as the class name.\n",
    "\n",
    "    Adjust this heuristic to match your naming scheme.\n",
    "    \"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    for delimiter in (\"_\", \"-\", \" \"):\n",
    "        if delimiter in stem:\n",
    "            return stem.split(delimiter)[0].lower()\n",
    "    return stem.lower()\n",
    "\n",
    "\n",
    "def discover_dataset(image_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Return a dataframe with columns [path, label].\"\"\"\n",
    "    image_paths = sorted(\n",
    "        p for p in image_dir.glob(\"**/*\") if p.is_file() and p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    )\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No images found in {image_dir}. Add files before running training.\"\n",
    "        )\n",
    "    records = []\n",
    "    for path in image_paths:\n",
    "        label = extract_label_from_name(path.name)\n",
    "        records.append({\"path\": path, \"label\": label})\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_dataset(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Print summary statistics and plot label distribution.\"\"\"\n",
    "    print(f\"Total images: {len(df)}\")\n",
    "    label_counts = df[\"label\"].value_counts().sort_values(ascending=False)\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(label_counts)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Image count per label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_val_test_split(\n",
    "    df: pd.DataFrame,\n",
    "    train_frac: float = 0.7,\n",
    "    val_frac: float = 0.2,\n",
    "    test_frac: float = 0.1,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the dataframe into train/validation/test subsets stratified by label.\n",
    "    For very small datasets (<20 images total), adjusts splits automatically.\n",
    "    \"\"\"\n",
    "    if not math.isclose(train_frac + val_frac + test_frac, 1.0, rel_tol=1e-5):\n",
    "        raise ValueError(\"train_frac + val_frac + test_frac must sum to 1.0\")\n",
    "\n",
    "    total_images = len(df)\n",
    "    num_classes = len(df[\"label\"].unique())\n",
    "    images_per_class = total_images // num_classes if num_classes > 0 else 0\n",
    "\n",
    "    # Adjust splits for very small datasets\n",
    "    if total_images < 20:\n",
    "        # For very small datasets, use larger train split, skip test if too small\n",
    "        train_frac = 0.85\n",
    "        val_frac = 0.15\n",
    "        test_frac = 0.0\n",
    "        print(f\"⚠️  Very small dataset detected ({total_images} images). Using adjusted splits: 85% train, 15% val, 0% test\")\n",
    "\n",
    "    df_shuffled = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    splits: Dict[str, List[pd.Series]] = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "    for label, group in df_shuffled.groupby(\"label\"):\n",
    "        n = len(group)\n",
    "        n_train = max(1, int(n * train_frac))\n",
    "        n_val = max(1, int(n * val_frac)) if n >= 3 and val_frac > 0 else 0\n",
    "        n_test = n - n_train - n_val if test_frac > 0 else 0\n",
    "        splits[\"train\"].append(group.iloc[:n_train])\n",
    "        if n_val > 0:\n",
    "            splits[\"val\"].append(group.iloc[n_train : n_train + n_val])\n",
    "        if n_test > 0:\n",
    "            splits[\"test\"].append(group.iloc[n_train + n_val :])\n",
    "\n",
    "    train_df = pd.concat(splits[\"train\"]).reset_index(drop=True)\n",
    "    val_df = pd.concat(splits[\"val\"]).reset_index(drop=True) if splits[\"val\"] else pd.DataFrame()\n",
    "    test_df = pd.concat(splits[\"test\"]).reset_index(drop=True) if splits[\"test\"] else pd.DataFrame()\n",
    "\n",
    "    print(\n",
    "        f\"Split counts -> train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\"\n",
    "    )\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset_df = discover_dataset(IMAGE_DIR)\n",
    "    display(dataset_df.head())\n",
    "    summarize_dataset(dataset_df)\n",
    "except FileNotFoundError as e:\n",
    "    dataset_df = None\n",
    "    print(e)\n",
    "    print(\"Populate the images directory and rerun this cell when ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d6ed1",
   "metadata": {},
   "source": [
    "## **2. Preprocessing Pipeline**\n",
    "\n",
    "This section builds TensorFlow `tf.data.Dataset` pipelines with on-the-fly preprocessing and optional augmentation. Adjust the image size or augmentations to suit your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def load_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Load an image from disk and resize it.\"\"\"\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    return image\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    class_to_index: Dict[str, int],\n",
    "    augment: bool = False,\n",
    "    aggressive_augment: bool = False,\n",
    "    very_small_dataset: bool = False,\n",
    ") -> tf.data.Dataset:\n",
    "    paths = df[\"path\"].astype(str).values\n",
    "    labels = df[\"label\"].map(class_to_index).values\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def _load_and_preprocess(path, label):\n",
    "        image = load_image(path)\n",
    "        if augment:\n",
    "            image = augment_image(image, aggressive=aggressive_augment, very_small_dataset=very_small_dataset)\n",
    "        return image, tf.one_hot(label, depth=len(class_to_index))\n",
    "\n",
    "    ds = ds.shuffle(len(df), seed=SEED)\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def augment_image(image: tf.Tensor, aggressive: bool = True, very_small_dataset: bool = False) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Apply data augmentation. \n",
    "    - aggressive=True: Standard aggressive augmentation\n",
    "    - very_small_dataset=True: Maximum augmentation for datasets <15 images per class\n",
    "    \"\"\"\n",
    "    # Random flips (always applied)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if very_small_dataset:\n",
    "        # MAXIMUM augmentation for very small datasets (11 images per class)\n",
    "        # Color augmentations\n",
    "        image = tf.image.random_brightness(image, max_delta=0.4)\n",
    "        image = tf.image.random_contrast(image, 0.6, 1.4)\n",
    "        image = tf.image.random_saturation(image, 0.5, 1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.15)\n",
    "        \n",
    "        # Geometric augmentations\n",
    "        # Random rotation (90 degree increments)\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
    "        \n",
    "        # Random zoom via crop and resize\n",
    "        crop_size = int(IMG_SIZE[0] * tf.random.uniform([], 0.7, 0.95))\n",
    "        if crop_size > 0:\n",
    "            image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n",
    "            image = tf.image.resize(image, IMG_SIZE)\n",
    "        \n",
    "        # Random translation (shift)\n",
    "        image = tf.image.random_crop(image, size=[int(IMG_SIZE[0]*0.9), int(IMG_SIZE[1]*0.9), 3])\n",
    "        image = tf.image.resize(image, IMG_SIZE)\n",
    "        \n",
    "    elif aggressive:\n",
    "        # Standard aggressive augmentation\n",
    "        image = tf.image.random_brightness(image, max_delta=0.3)\n",
    "        image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "        image = tf.image.random_saturation(image, 0.6, 1.4)\n",
    "        image = tf.image.random_hue(image, max_delta=0.1)\n",
    "        # Random rotation (90 degree increments)\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
    "        # Random zoom via crop and resize\n",
    "        crop_size = int(IMG_SIZE[0] * 0.8)\n",
    "        if crop_size > 0:\n",
    "            image = tf.image.random_crop(image, size=[crop_size, crop_size, 3])\n",
    "            image = tf.image.resize(image, IMG_SIZE)\n",
    "    else:\n",
    "        # Mild augmentation\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "        image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    \n",
    "    # Ensure values stay in [0, 1]\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare_datasets(df: pd.DataFrame):\n",
    "    labels = sorted(df[\"label\"].unique())\n",
    "    class_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "    index_to_class = {idx: label for label, idx in class_to_index.items()}\n",
    "\n",
    "    # Detect dataset size and choose augmentation strategy\n",
    "    total_images = len(df)\n",
    "    num_classes = len(labels)\n",
    "    images_per_class = total_images // num_classes if num_classes > 0 else 0\n",
    "    \n",
    "    # Determine augmentation level\n",
    "    use_very_small_aug = images_per_class < 15  # Maximum augmentation for very small datasets\n",
    "    use_aggressive_aug = images_per_class < 50 and not use_very_small_aug  # Standard aggressive for small datasets\n",
    "\n",
    "    train_df, val_df, test_df = train_val_test_split(df)\n",
    "\n",
    "    train_ds = build_dataset(\n",
    "        train_df, \n",
    "        class_to_index, \n",
    "        augment=True, \n",
    "        aggressive_augment=use_aggressive_aug,\n",
    "        very_small_dataset=use_very_small_aug\n",
    "    )\n",
    "    val_ds = build_dataset(val_df, class_to_index, augment=False) if len(val_df) else None\n",
    "    test_ds = build_dataset(test_df, class_to_index, augment=False) if len(test_df) else None\n",
    "\n",
    "    return {\n",
    "        \"train\": train_ds,\n",
    "        \"val\": val_ds,\n",
    "        \"test\": test_ds,\n",
    "        \"class_to_index\": class_to_index,\n",
    "        \"index_to_class\": index_to_class,\n",
    "        \"train_df\": train_df,\n",
    "        \"val_df\": val_df,\n",
    "        \"test_df\": test_df,\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
