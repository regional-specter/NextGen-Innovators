{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bac1908",
   "metadata": {},
   "source": [
    "# Visual Sound Detection Model\n",
    "\n",
    "This notebook builds a computer vision classifier that learns from images located in the `images` folder. Each image file name is interpreted as its label. The pipeline covers environment setup, data ingestion, preprocessing, model training, evaluation, and an optional realtime webcam inference demo.\n",
    "\n",
    "> **Note:** Add your images to `images/` before running the training steps. The notebook assumes a standard RGB image format (e.g., `.jpg`, `.png`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c221ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: used later for webcam capture\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    cv2 = None\n",
    "    print(\"OpenCV (cv2) not found. Webcam inference cell will guide you through installing it.\")\n",
    "\n",
    "# Configure paths\n",
    "PROJECT_ROOT = Path(\"/Users/raoabdul/Documents/Development/NextGen-Innovators\")\n",
    "IMAGE_DIR = PROJECT_ROOT / \"images\"\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Basic reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Looking for images in: {IMAGE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26daff",
   "metadata": {},
   "source": [
    "## 1. Dataset Discovery & Label Parsing\n",
    "\n",
    "This section scans the `images` directory, extracts labels from file names, and builds a dataframe describing the dataset. Customize `extract_label_from_name` if you prefer a different naming convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f05ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_name(filename: str) -> str:\n",
    "    \"\"\"Derive a label from the image filename (without the extension).\n",
    "\n",
    "    Strategy:\n",
    "      1. Remove the file extension.\n",
    "      2. Split on underscores, dashes, or spaces.\n",
    "      3. Use the first token as the class name.\n",
    "\n",
    "    Adjust this heuristic to match your naming scheme.\n",
    "    \"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    for delimiter in (\"_\", \"-\", \" \"):\n",
    "        if delimiter in stem:\n",
    "            return stem.split(delimiter)[0].lower()\n",
    "    return stem.lower()\n",
    "\n",
    "\n",
    "def discover_dataset(image_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Return a dataframe with columns [path, label].\"\"\"\n",
    "    image_paths = sorted(\n",
    "        p for p in image_dir.glob(\"**/*\") if p.is_file() and p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    )\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No images found in {image_dir}. Add files before running training.\"\n",
    "        )\n",
    "    records = []\n",
    "    for path in image_paths:\n",
    "        label = extract_label_from_name(path.name)\n",
    "        records.append({\"path\": path, \"label\": label})\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_dataset(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Print summary statistics and plot label distribution.\"\"\"\n",
    "    print(f\"Total images: {len(df)}\")\n",
    "    label_counts = df[\"label\"].value_counts().sort_values(ascending=False)\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(label_counts)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Image count per label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_val_test_split(\n",
    "    df: pd.DataFrame,\n",
    "    train_frac: float = 0.7,\n",
    "    val_frac: float = 0.2,\n",
    "    test_frac: float = 0.1,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split the dataframe into train/validation/test subsets stratified by label.\"\"\"\n",
    "    if not math.isclose(train_frac + val_frac + test_frac, 1.0, rel_tol=1e-5):\n",
    "        raise ValueError(\"train_frac + val_frac + test_frac must sum to 1.0\")\n",
    "\n",
    "    df_shuffled = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    splits: Dict[str, List[pd.Series]] = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "    for label, group in df_shuffled.groupby(\"label\"):\n",
    "        n = len(group)\n",
    "        n_train = max(1, int(n * train_frac))\n",
    "        n_val = max(1, int(n * val_frac)) if n >= 3 else 0\n",
    "        n_test = n - n_train - n_val\n",
    "        splits[\"train\"].append(group.iloc[:n_train])\n",
    "        splits[\"val\"].append(group.iloc[n_train : n_train + n_val])\n",
    "        splits[\"test\"].append(group.iloc[n_train + n_val :])\n",
    "\n",
    "    train_df = pd.concat(splits[\"train\"]).reset_index(drop=True)\n",
    "    val_df = pd.concat(splits[\"val\"]).reset_index(drop=True)\n",
    "    test_df = pd.concat(splits[\"test\"]).reset_index(drop=True)\n",
    "\n",
    "    print(\n",
    "        f\"Split counts -> train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\"\n",
    "    )\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45655c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset_df = discover_dataset(IMAGE_DIR)\n",
    "    display(dataset_df.head())\n",
    "    summarize_dataset(dataset_df)\n",
    "except FileNotFoundError as e:\n",
    "    dataset_df = None\n",
    "    print(e)\n",
    "    print(\"Populate the images directory and rerun this cell when ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046c7e7",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline\n",
    "\n",
    "This section builds TensorFlow `tf.data.Dataset` pipelines with on-the-fly preprocessing and optional augmentation. Adjust the image size or augmentations to suit your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def load_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Load an image from disk and resize it.\"\"\"\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    return image\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    class_to_index: Dict[str, int],\n",
    "    augment: bool = False,\n",
    ") -> tf.data.Dataset:\n",
    "    paths = df[\"path\"].astype(str).values\n",
    "    labels = df[\"label\"].map(class_to_index).values\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def _load_and_preprocess(path, label):\n",
    "        image = load_image(path)\n",
    "        if augment:\n",
    "            image = augment_image(image)\n",
    "        return image, tf.one_hot(label, depth=len(class_to_index))\n",
    "\n",
    "    ds = ds.shuffle(len(df), seed=SEED)\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def augment_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare_datasets(df: pd.DataFrame):\n",
    "    labels = sorted(df[\"label\"].unique())\n",
    "    class_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "    index_to_class = {idx: label for label, idx in class_to_index.items()}\n",
    "\n",
    "    train_df, val_df, test_df = train_val_test_split(df)\n",
    "\n",
    "    train_ds = build_dataset(train_df, class_to_index, augment=True)\n",
    "    val_ds = build_dataset(val_df, class_to_index, augment=False) if len(val_df) else None\n",
    "    test_ds = build_dataset(test_df, class_to_index, augment=False) if len(test_df) else None\n",
    "\n",
    "    return {\n",
    "        \"train\": train_ds,\n",
    "        \"val\": val_ds,\n",
    "        \"test\": test_ds,\n",
    "        \"class_to_index\": class_to_index,\n",
    "        \"index_to_class\": index_to_class,\n",
    "        \"train_df\": train_df,\n",
    "        \"val_df\": val_df,\n",
    "        \"test_df\": test_df,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5626e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_df is not None:\n",
    "    data_bundle = prepare_datasets(dataset_df)\n",
    "else:\n",
    "    data_bundle = None\n",
    "    print(\"Dataset not prepared yet. Populate images and rerun.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd88329",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "We define a compact convolutional neural network suitable for small to medium datasets. Swap in transfer learning (e.g., EfficientNet) if you need higher performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(num_classes: int) -> keras.Model:\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"visual_classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if data_bundle is not None:\n",
    "    num_classes = len(data_bundle[\"class_to_index\"])\n",
    "    model = build_classifier(num_classes)\n",
    "    model.summary()\n",
    "else:\n",
    "    model = None\n",
    "    print(\"Model not built yet. Prepare datasets first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2264abc",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "Define callbacks, train the model, and capture the training history. Adjust epochs or callbacks for your dataset size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "if data_bundle is not None and model is not None:\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(ARTIFACT_DIR / \"visual_classifier.keras\"),\n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        data_bundle[\"train\"],\n",
    "        validation_data=data_bundle[\"val\"],\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "else:\n",
    "    history = None\n",
    "    print(\"Training skipped. Ensure datasets and model are initialized above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: keras.callbacks.History) -> None:\n",
    "    metrics = [\"accuracy\", \"loss\"]\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for idx, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(1, 2, idx)\n",
    "        plt.plot(history.history[metric], label=f\"train_{metric}\")\n",
    "        val_metric = f\"val_{metric}\"\n",
    "        if val_metric in history.history:\n",
    "            plt.plot(history.history[val_metric], label=f\"val_{metric}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if history is not None:\n",
    "    plot_history(history)\n",
    "else:\n",
    "    print(\"No training history to plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bde3ed",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Diagnostics\n",
    "\n",
    "Run evaluation on the held-out test set, visualize predictions, and inspect the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate_model(model: keras.Model, data_bundle: dict) -> Dict[str, np.ndarray]:\n",
    "    test_ds = data_bundle[\"test\"]\n",
    "    if test_ds is None:\n",
    "        raise ValueError(\"Test dataset is empty. Provide more images per class.\")\n",
    "\n",
    "    test_results = model.evaluate(test_ds, verbose=1)\n",
    "    print(dict(zip(model.metrics_names, test_results)))\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_ds:\n",
    "        logits = model.predict(images, verbose=0)\n",
    "        y_true.extend(tf.argmax(labels, axis=1).numpy())\n",
    "        y_pred.extend(tf.argmax(logits, axis=1).numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=[data_bundle[\"index_to_class\"][i] for i in range(len(data_bundle[\"index_to_class\"]))],\n",
    "        digits=4,\n",
    "    )\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[data_bundle[\"index_to_class\"][i] for i in range(len(cm))],\n",
    "        yticklabels=[data_bundle[\"index_to_class\"][i] for i in range(len(cm))],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"y_true\": y_true, \"y_pred\": y_pred, \"cm\": cm}\n",
    "\n",
    "\n",
    "if model is not None and data_bundle is not None and data_bundle[\"test\"] is not None:\n",
    "    evaluation_outputs = evaluate_model(model, data_bundle)\n",
    "else:\n",
    "    evaluation_outputs = None\n",
    "    print(\"Evaluation skipped. Ensure model is trained and test set is available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ec221",
   "metadata": {},
   "source": [
    "## 6. Single Image Inference Helper\n",
    "\n",
    "Use the helper below to classify individual images. Provide a path to any image file after training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(path: Path, model: keras.Model, index_to_class: Dict[int, str]) -> Dict[str, float]:\n",
    "    image = load_image(tf.convert_to_tensor(str(path)))\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    preds = model.predict(image, verbose=0)[0]\n",
    "    return {\n",
    "        index_to_class[idx]: float(prob)\n",
    "        for idx, prob in enumerate(preds)\n",
    "    }\n",
    "\n",
    "\n",
    "def display_prediction(predictions: Dict[str, float]) -> None:\n",
    "    items = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    for label, prob in items:\n",
    "        print(f\"{label}: {prob:.3f}\")\n",
    "\n",
    "\n",
    "# Example usage (update the path after adding images)\n",
    "example_image_path = IMAGE_DIR / \"sample_image.jpg\"\n",
    "if model is not None and example_image_path.exists():\n",
    "    probs = predict_image(example_image_path, model, data_bundle[\"index_to_class\"])\n",
    "    display_prediction(probs)\n",
    "else:\n",
    "    print(\"Set `example_image_path` to an existing image after training to see predictions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2825b94",
   "metadata": {},
   "source": [
    "## 7. Realtime Webcam Inference (Optional)\n",
    "\n",
    "The cell below captures frames from your default webcam, runs classification, and overlays the predicted label. Install OpenCV (`pip install opencv-python`) if it's not already available. Press `q` to quit the loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cv2 is None:\n",
    "    print(\"OpenCV is not installed. Run `pip install opencv-python` and restart the kernel before executing this cell.\")\n",
    "elif model is None or data_bundle is None:\n",
    "    print(\"Train the model before running webcam inference.\")\n",
    "else:\n",
    "    label_colors = {\n",
    "        label: tuple(np.random.randint(0, 255, size=3).tolist())\n",
    "        for label in data_bundle[\"class_to_index\"].keys()\n",
    "    }\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Unable to access the webcam. Check camera permissions or device connection.\")\n",
    "    else:\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Failed to read frame from webcam.\")\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                pil_image = Image.fromarray(rgb_frame)\n",
    "                resized = pil_image.resize(IMG_SIZE)\n",
    "                input_arr = np.array(resized, dtype=np.float32) / 255.0\n",
    "                input_arr = np.expand_dims(input_arr, axis=0)\n",
    "\n",
    "                preds = model.predict(input_arr, verbose=0)[0]\n",
    "                best_idx = int(np.argmax(preds))\n",
    "                best_label = data_bundle[\"index_to_class\"][best_idx]\n",
    "                best_prob = float(preds[best_idx])\n",
    "\n",
    "                text = f\"{best_label}: {best_prob:.2f}\"\n",
    "                color = label_colors[best_label]\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    text,\n",
    "                    (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.0,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "                cv2.imshow(\"Realtime Classification\", frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b92e7",
   "metadata": {},
   "source": [
    "## 8. Save and Reload Model\n",
    "\n",
    "Persist the trained model and provide a simple loader. This allows you to reuse the classifier without retraining every session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ARTIFACT_DIR / \"visual_classifier.keras\"\n",
    "METADATA_PATH = ARTIFACT_DIR / \"class_mapping.json\"\n",
    "\n",
    "if model is not None and data_bundle is not None:\n",
    "    model.save(MODEL_PATH)\n",
    "    with open(METADATA_PATH, \"w\") as f:\n",
    "        json.dump(data_bundle[\"index_to_class\"], f, indent=2)\n",
    "    print(f\"Model saved to {MODEL_PATH}\")\n",
    "    print(f\"Class mapping saved to {METADATA_PATH}\")\n",
    "else:\n",
    "    print(\"Model not saved. Train the model first.\")\n",
    "\n",
    "\n",
    "def load_model_and_mapping(model_path: Path, metadata_path: Path):\n",
    "    loaded_model = keras.models.load_model(model_path)\n",
    "    with open(metadata_path) as f:\n",
    "        index_to_class = {int(k): v for k, v in json.load(f).items()}\n",
    "    return loaded_model, index_to_class\n",
    "\n",
    "\n",
    "# Example reload usage (uncomment after training and saving)\n",
    "# reloaded_model, index_to_class = load_model_and_mapping(MODEL_PATH, METADATA_PATH)\n",
    "# display_prediction(predict_image(example_image_path, reloaded_model, index_to_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41943af",
   "metadata": {},
   "source": [
    "## 9. Next Steps Checklist\n",
    "\n",
    "- Add class-balanced images into `images/`.\n",
    "- Run the notebook sequentially from top to bottom.\n",
    "- Monitor training curves and adjust hyperparameters as needed.\n",
    "- Test with realtime webcam inference once satisfied with model accuracy.\n",
    "- Consider augmenting the dataset or using transfer learning for improved performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
